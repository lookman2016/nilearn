
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta charset="utf-8" />
    <title>Nilearn: Machine learning for NeuroImaging in Python &#8212; Machine learning for NeuroImaging</title>
    <link rel="stylesheet" href="../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/language_data.js"></script>
    <script type="text/javascript" src="../../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="7.6.3. nilearn.input_data.NiftiLabelsMasker" href="nilearn.input_data.NiftiLabelsMasker.html" />
    <link rel="prev" title="7.6.1. nilearn.input_data.NiftiMasker" href="nilearn.input_data.NiftiMasker.html" />
<meta content="True" name="HandheldFriendly">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
<meta name="keywords" content="nilearn, neuroimaging, python, neuroscience, machinelearning">


<script type="text/javascript">
function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});
</script>
<script type="text/javascript">
function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});
</script>


<script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>

  </head><body>
<div id="logo-banner">
  <div class="logo">
    <a href="../../index.html">
      <img src="../../_static/nilearn-logo.png" alt="Nilearn logo"  border="0" />
    </a>
  </div>
  <!-- A tag cloud to make it easy for people to find what they are
                         looking for -->
 <div class="tags">
  <ul>
    <li>
      <big><a href="../../auto_examples/decoding/plot_haxby_anova_svm.html">SVM</a></big>
    </li>
    <li>
      <small><a href="../../connectivity/parcellating.html">Ward
          clustering</a></small>
    </li>
    <li>
      <a href="../../decoding/searchlight.html">Searchlight</a>
    </li>
    <li>
      <big><a href="../../connectivity/resting_state_networks.html">ICA</a></big>
    </li>
    <li>
      <a href="../../manipulating_images/data_preparation.html">Nifti IO</a>
    </li>
    <li>
      <a href="../reference.html#module-nilearn.datasets">Datasets</a>
    </li>
  </ul>
 </div>

  <div class="banner">
    <h1>Nilearn:</h1>
    <h2>Machine learning for Neuro-Imaging in Python</h2>
  </div>
  <div class="search_form">
    <div class="gcse-search" id="cse" style="width: 100%;"></div>
    <script>
      (function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();
    </script>
  </div>
</div>



<div class=related-wrapper>
    
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="nilearn.input_data.NiftiLabelsMasker.html" title="7.6.3. nilearn.input_data.NiftiLabelsMasker"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="nilearn.input_data.NiftiMasker.html" title="7.6.1. nilearn.input_data.NiftiMasker"
             accesskey="P">previous</a> |</li>
<li><a href="../../index.html">Nilearn Home</a> |&nbsp;</li>
<li><a href="../../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../../auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="../reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../../authors.html">About</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li class="nav-item nav-item-1"><a href="../../user_guide.html" >User guide: table of contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../reference.html" accesskey="U"><span class="section-number">7. </span>Reference documentation: all nilearn functions</a> &#187;</li> 
      </ul>
    </div>
</div>

      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">


<h4> Giving credit </h4>
  <ul class="simple">
    <li><p>Please consider <a href="../../authors.html#citing">citing the
                    papers</a>.</p></li>
  </ul>

  <h3><a href="../../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">7.6.2. nilearn.input_data.MultiNiftiMasker</a><ul>
<li><a class="reference internal" href="#examples-using-nilearn-input-data-multiniftimasker">7.6.2.1. Examples using <code class="docutils literal notranslate"><span class="pre">nilearn.input_data.MultiNiftiMasker</span></code></a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="nilearn.input_data.NiftiMasker.html"
                        title="previous chapter"><span class="section-number">7.6.1. </span>nilearn.input_data.NiftiMasker</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="nilearn.input_data.NiftiLabelsMasker.html"
                        title="next chapter"><span class="section-number">7.6.3. </span>nilearn.input_data.NiftiLabelsMasker</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="admonition note">
<p class="admonition-title">Note</p>
<p>This page is a reference documentation. It only explains the class
signature, and not how to use it. Please refer to the
<a class="reference internal" href="../../user_guide.html#user-guide"><span class="std std-ref">user guide</span></a> for the big picture.</p>
</div>
<div class="section" id="nilearn-input-data-multiniftimasker">
<h1><span class="section-number">7.6.2. </span>nilearn.input_data.MultiNiftiMasker<a class="headerlink" href="#nilearn-input-data-multiniftimasker" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="nilearn.input_data.MultiNiftiMasker">
<em class="property">class </em><code class="sig-prename descclassname">nilearn.input_data.</code><code class="sig-name descname">MultiNiftiMasker</code><span class="sig-paren">(</span><em class="sig-param">mask_img=None</em>, <em class="sig-param">smoothing_fwhm=None</em>, <em class="sig-param">standardize=False</em>, <em class="sig-param">detrend=False</em>, <em class="sig-param">low_pass=None</em>, <em class="sig-param">high_pass=None</em>, <em class="sig-param">t_r=None</em>, <em class="sig-param">target_affine=None</em>, <em class="sig-param">target_shape=None</em>, <em class="sig-param">mask_strategy='background'</em>, <em class="sig-param">mask_args=None</em>, <em class="sig-param">dtype=None</em>, <em class="sig-param">memory=Memory(location=None)</em>, <em class="sig-param">memory_level=0</em>, <em class="sig-param">n_jobs=1</em>, <em class="sig-param">verbose=0</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.input_data.MultiNiftiMasker" title="Permalink to this definition">¶</a></dt>
<dd><p>Class for masking of Niimg-like objects.</p>
<p>MultiNiftiMasker is useful when dealing with image sets from multiple
subjects. Use case: integrates well with decomposition by MultiPCA and
CanICA (multi-subject models)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>mask_img: Niimg-like object</strong></dt><dd><p>See <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">http://nilearn.github.io/manipulating_images/input_output.html</a>
Mask of the data. If not given, a mask is computed in the fit step.
Optional parameters can be set using mask_args and mask_strategy to
fine tune the mask extraction.</p>
</dd>
<dt><strong>smoothing_fwhm: float, optional</strong></dt><dd><p>If smoothing_fwhm is not None, it gives the size in millimeters of
the spatial smoothing to apply to the signal.</p>
</dd>
<dt><strong>standardize: {‘zscore’, ‘psc’, True, False}, default is ‘zscore’</strong></dt><dd><p>Strategy to standardize the signal.
‘zscore’: the signal is z-scored. Timeseries are shifted
to zero mean and scaled to unit variance.
‘psc’:  Timeseries are shifted to zero mean value and scaled
to percent signal change (as compared to original mean signal).
True : the signal is z-scored. Timeseries are shifted
to zero mean and scaled to unit variance.
False : Do not standardize the data.</p>
</dd>
<dt><strong>detrend: boolean, optional</strong></dt><dd><p>This parameter is passed to signal.clean. Please see the related
documentation for details</p>
</dd>
<dt><strong>low_pass: None or float, optional</strong></dt><dd><p>This parameter is passed to signal.clean. Please see the related
documentation for details</p>
</dd>
<dt><strong>high_pass: None or float, optional</strong></dt><dd><p>This parameter is passed to signal.clean. Please see the related
documentation for details</p>
</dd>
<dt><strong>t_r: float, optional</strong></dt><dd><p>This parameter is passed to signal.clean. Please see the related
documentation for details</p>
</dd>
<dt><strong>target_affine: 3x3 or 4x4 matrix, optional</strong></dt><dd><p>This parameter is passed to image.resample_img. Please see the
related documentation for details.</p>
</dd>
<dt><strong>target_shape: 3-tuple of integers, optional</strong></dt><dd><p>This parameter is passed to image.resample_img. Please see the
related documentation for details.</p>
</dd>
<dt><strong>mask_strategy: {‘background’, ‘epi’ or ‘template’}, optional</strong></dt><dd><p>The strategy used to compute the mask: use ‘background’ if your
images present a clear homogeneous background, ‘epi’ if they
are raw EPI images, or you could use ‘template’ which will
extract the gray matter part of your data by resampling the MNI152
brain mask for your data’s field of view.
Depending on this value, the mask will be computed from
masking.compute_background_mask, masking.compute_epi_mask or
masking.compute_gray_matter_mask. Default is ‘background’.</p>
</dd>
<dt><strong>mask_args</strong><span class="classifier">dict, optional</span></dt><dd><p>If mask is None, these are additional parameters passed to
masking.compute_background_mask or masking.compute_epi_mask
to fine-tune mask computation. Please see the related documentation
for details.</p>
</dd>
<dt><strong>dtype: {dtype, “auto”}</strong></dt><dd><p>Data type toward which the data should be converted. If “auto”, the
data will be converted to int32 if dtype is discrete and float32 if it
is continuous.</p>
</dd>
<dt><strong>memory: instance of joblib.Memory or string</strong></dt><dd><p>Used to cache the masking process.
By default, no caching is done. If a string is given, it is the
path to the caching directory.</p>
</dd>
<dt><strong>memory_level: integer, optional</strong></dt><dd><p>Rough estimator of the amount of memory used by caching. Higher value
means more memory for caching.</p>
</dd>
<dt><strong>n_jobs: integer, optional</strong></dt><dd><p>The number of CPUs to use to do the computation. -1 means
‘all CPUs’, -2 ‘all CPUs but one’, and so on.</p>
</dd>
<dt><strong>verbose: integer, optional</strong></dt><dd><p>Indicate the level of verbosity. By default, nothing is printed</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="nilearn.image.resample_img.html#nilearn.image.resample_img" title="nilearn.image.resample_img"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nilearn.image.resample_img</span></code></a></dt><dd><p>image resampling</p>
</dd>
<dt><a class="reference internal" href="nilearn.masking.compute_epi_mask.html#nilearn.masking.compute_epi_mask" title="nilearn.masking.compute_epi_mask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nilearn.masking.compute_epi_mask</span></code></a></dt><dd><p>mask computation</p>
</dd>
<dt><a class="reference internal" href="nilearn.masking.apply_mask.html#nilearn.masking.apply_mask" title="nilearn.masking.apply_mask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nilearn.masking.apply_mask</span></code></a></dt><dd><p>mask application on image</p>
</dd>
<dt><a class="reference internal" href="nilearn.signal.clean.html#nilearn.signal.clean" title="nilearn.signal.clean"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nilearn.signal.clean</span></code></a></dt><dd><p>confounds removal and general filtering of signals</p>
</dd>
</dl>
</div>
<dl class="field-list simple">
<dt class="field-odd">Attributes</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>`mask_img_`</strong><span class="classifier">nibabel.Nifti1Image object</span></dt><dd><p>The mask of the data.</p>
</dd>
<dt><strong>`affine_`</strong><span class="classifier">4x4 numpy.ndarray</span></dt><dd><p>Affine of the transformed image.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="method">
<dt id="nilearn.input_data.MultiNiftiMasker.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">mask_img=None</em>, <em class="sig-param">smoothing_fwhm=None</em>, <em class="sig-param">standardize=False</em>, <em class="sig-param">detrend=False</em>, <em class="sig-param">low_pass=None</em>, <em class="sig-param">high_pass=None</em>, <em class="sig-param">t_r=None</em>, <em class="sig-param">target_affine=None</em>, <em class="sig-param">target_shape=None</em>, <em class="sig-param">mask_strategy='background'</em>, <em class="sig-param">mask_args=None</em>, <em class="sig-param">dtype=None</em>, <em class="sig-param">memory=Memory(location=None)</em>, <em class="sig-param">memory_level=0</em>, <em class="sig-param">n_jobs=1</em>, <em class="sig-param">verbose=0</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.input_data.MultiNiftiMasker.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize self.  See help(type(self)) for accurate signature.</p>
</dd></dl>

<dl class="method">
<dt id="nilearn.input_data.MultiNiftiMasker.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">imgs=None</em>, <em class="sig-param">y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.input_data.MultiNiftiMasker.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the mask corresponding to the data</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>imgs: list of Niimg-like objects</strong></dt><dd><p>See <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">http://nilearn.github.io/manipulating_images/input_output.html</a>
Data on which the mask must be calculated. If this is a list,
the affine is considered the same for all.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nilearn.input_data.MultiNiftiMasker.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">X</em>, <em class="sig-param">y=None</em>, <em class="sig-param">confounds=None</em>, <em class="sig-param">**fit_params</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.input_data.MultiNiftiMasker.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">Niimg-like object</span></dt><dd><p>See <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">http://nilearn.github.io/manipulating_images/input_output.html</a></p>
</dd>
<dt><strong>y</strong><span class="classifier">numpy array of shape [n_samples]</span></dt><dd><p>Target values.</p>
</dd>
<dt><strong>confounds: list of confounds, optional</strong></dt><dd><p>List of confounds (2D arrays or filenames pointing to CSV
files). Must be of same length than imgs_list.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>X_new</strong><span class="classifier">numpy array of shape [n_samples, n_features_new]</span></dt><dd><p>Transformed array.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nilearn.input_data.MultiNiftiMasker.generate_report">
<code class="sig-name descname">generate_report</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.input_data.MultiNiftiMasker.generate_report" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a report for Nilearn objects.</p>
<p>Reports are useful to visualize steps in a processing pipeline.
Example use case: visualize the overlap of a mask and reference image
in NiftiMasker.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>report</strong><span class="classifier">HTMLReport</span></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nilearn.input_data.MultiNiftiMasker.get_params">
<code class="sig-name descname">get_params</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.input_data.MultiNiftiMasker.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>deep</strong><span class="classifier">bool, default=True</span></dt><dd><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>params</strong><span class="classifier">mapping of string to any</span></dt><dd><p>Parameter names mapped to their values.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nilearn.input_data.MultiNiftiMasker.inverse_transform">
<code class="sig-name descname">inverse_transform</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">X</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.input_data.MultiNiftiMasker.inverse_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform the 2D data matrix back to an image in brain space.</p>
</dd></dl>

<dl class="method">
<dt id="nilearn.input_data.MultiNiftiMasker.set_params">
<code class="sig-name descname">set_params</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">**params</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.input_data.MultiNiftiMasker.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s possible to update each
component of a nested object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>**params</strong><span class="classifier">dict</span></dt><dd><p>Estimator parameters.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">object</span></dt><dd><p>Estimator instance.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nilearn.input_data.MultiNiftiMasker.transform">
<code class="sig-name descname">transform</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">imgs</em>, <em class="sig-param">confounds=None</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.input_data.MultiNiftiMasker.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply mask, spatial and temporal preprocessing</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>imgs: list of Niimg-like objects</strong></dt><dd><p>See <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">http://nilearn.github.io/manipulating_images/input_output.html</a>
Data to be preprocessed</p>
</dd>
<dt><strong>confounds: CSV file path or 2D matrix</strong></dt><dd><p>This parameter is passed to signal.clean. Please see the
corresponding documentation for details.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>data: {list of numpy arrays}</dt><dd><p>preprocessed images</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nilearn.input_data.MultiNiftiMasker.transform_imgs">
<code class="sig-name descname">transform_imgs</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">imgs_list</em>, <em class="sig-param">confounds=None</em>, <em class="sig-param">copy=True</em>, <em class="sig-param">n_jobs=1</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.input_data.MultiNiftiMasker.transform_imgs" title="Permalink to this definition">¶</a></dt>
<dd><p>Prepare multi subject data in parallel</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>imgs_list: list of Niimg-like objects</strong></dt><dd><p>See <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">http://nilearn.github.io/manipulating_images/input_output.html</a>
List of imgs file to prepare. One item per subject.</p>
</dd>
<dt><strong>confounds: list of confounds, optional</strong></dt><dd><p>List of confounds (2D arrays or filenames pointing to CSV
files). Must be of same length than imgs_list.</p>
</dd>
<dt><strong>copy: boolean, optional</strong></dt><dd><p>If True, guarantees that output array has no memory in common with
input array.</p>
</dd>
<dt><strong>n_jobs: integer, optional</strong></dt><dd><p>The number of cpus to use to do the computation. -1 means
‘all cpus’.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>region_signals: list of 2D numpy.ndarray</dt><dd><p>List of signal for each element per subject.
shape: list of (number of scans, number of elements)</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nilearn.input_data.MultiNiftiMasker.transform_single_imgs">
<code class="sig-name descname">transform_single_imgs</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">imgs</em>, <em class="sig-param">confounds=None</em>, <em class="sig-param">copy=True</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.input_data.MultiNiftiMasker.transform_single_imgs" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply mask, spatial and temporal preprocessing</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>imgs: 3D/4D Niimg-like object</strong></dt><dd><p>See <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">http://nilearn.github.io/manipulating_images/input_output.html</a>
Images to process. It must boil down to a 4D image with scans
number as last dimension.</p>
</dd>
<dt><strong>confounds: CSV file or array-like, optional</strong></dt><dd><p>This parameter is passed to signal.clean. Please see the related
documentation for details: <a class="reference internal" href="nilearn.signal.clean.html#nilearn.signal.clean" title="nilearn.signal.clean"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.signal.clean</span></code></a>.
shape: (number of scans, number of confounds)</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>region_signals: 2D numpy.ndarray</dt><dd><p>Signal for each voxel inside the mask.
shape: (number of scans, number of voxels)</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<div class="section" id="examples-using-nilearn-input-data-multiniftimasker">
<h2><span class="section-number">7.6.2.1. </span>Examples using <code class="docutils literal notranslate"><span class="pre">nilearn.input_data.MultiNiftiMasker</span></code><a class="headerlink" href="#examples-using-nilearn-input-data-multiniftimasker" title="Permalink to this headline">¶</a></h2>
<div class="sphx-glr-thumbcontainer" tooltip="This example partly reproduces the encoding model presented in     `Visual image reconstruction..."><div class="figure align-default" id="id1">
<img alt="../../_images/sphx_glr_plot_miyawaki_encoding_thumb.png" src="../../_images/sphx_glr_plot_miyawaki_encoding_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_miyawaki_encoding.html#sphx-glr-auto-examples-02-decoding-plot-miyawaki-encoding-py"><span class="std std-ref">Encoding models for visual stimuli from Miyawaki et al. 2008</span></a></span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example reproduces the experiment presented in     `Visual image reconstruction from human..."><div class="figure align-default" id="id2">
<img alt="../../_images/sphx_glr_plot_miyawaki_reconstruction_thumb.png" src="../../_images/sphx_glr_plot_miyawaki_reconstruction_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_miyawaki_reconstruction.html#sphx-glr-auto-examples-02-decoding-plot-miyawaki-reconstruction-py"><span class="std std-ref">Reconstruction of visual stimuli from Miyawaki et al. 2008</span></a></span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</div>
</div><div style='clear:both'></div></div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>

    <div class="footer">
            &copy; The nilearn developers 2010-2015.
          Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 2.3.1.
        <span style="padding-left: 5ex;">
          <a href="../../_sources/modules/generated/nilearn.input_data.MultiNiftiMasker.rst.txt"
        	 rel="nofollow">Show this page source</a>
        </span>
    </div>
  </body>
</html>