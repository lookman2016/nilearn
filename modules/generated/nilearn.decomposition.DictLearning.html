
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta charset="utf-8" />
    <title>Nilearn: Machine learning for NeuroImaging in Python &#8212; Machine learning for NeuroImaging</title>
    <link rel="stylesheet" href="../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/language_data.js"></script>
    <script type="text/javascript" src="../../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="7.5.1. nilearn.image.clean_img" href="nilearn.image.clean_img.html" />
    <link rel="prev" title="7.4.1. nilearn.decomposition.CanICA" href="nilearn.decomposition.CanICA.html" />
<meta content="True" name="HandheldFriendly">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
<meta name="keywords" content="nilearn, neuroimaging, python, neuroscience, machinelearning">


<script type="text/javascript">
function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});
</script>
<script type="text/javascript">
function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});
</script>


<script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>

  </head><body>
<div id="logo-banner">
  <div class="logo">
    <a href="../../index.html">
      <img src="../../_static/nilearn-logo.png" alt="Nilearn logo"  border="0" />
    </a>
  </div>
  <!-- A tag cloud to make it easy for people to find what they are
                         looking for -->
 <div class="tags">
  <ul>
    <li>
      <big><a href="../../auto_examples/decoding/plot_haxby_anova_svm.html">SVM</a></big>
    </li>
    <li>
      <small><a href="../../connectivity/parcellating.html">Ward
          clustering</a></small>
    </li>
    <li>
      <a href="../../decoding/searchlight.html">Searchlight</a>
    </li>
    <li>
      <big><a href="../../connectivity/resting_state_networks.html">ICA</a></big>
    </li>
    <li>
      <a href="../../manipulating_images/data_preparation.html">Nifti IO</a>
    </li>
    <li>
      <a href="../reference.html#module-nilearn.datasets">Datasets</a>
    </li>
  </ul>
 </div>

  <div class="banner">
    <h1>Nilearn:</h1>
    <h2>Machine learning for Neuro-Imaging in Python</h2>
  </div>
  <div class="search_form">
    <div class="gcse-search" id="cse" style="width: 100%;"></div>
    <script>
      (function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();
    </script>
  </div>
</div>



<div class=related-wrapper>
    
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="nilearn.image.clean_img.html" title="7.5.1. nilearn.image.clean_img"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="nilearn.decomposition.CanICA.html" title="7.4.1. nilearn.decomposition.CanICA"
             accesskey="P">previous</a> |</li>
<li><a href="../../index.html">Nilearn Home</a> |&nbsp;</li>
<li><a href="../../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../../auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="../reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../../authors.html">About</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li class="nav-item nav-item-1"><a href="../../user_guide.html" >User guide: table of contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../reference.html" accesskey="U"><span class="section-number">7. </span>Reference documentation: all nilearn functions</a> &#187;</li> 
      </ul>
    </div>
</div>

      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">


<h4> Giving credit </h4>
  <ul class="simple">
    <li><p>Please consider <a href="../../authors.html#citing">citing the
                    papers</a>.</p></li>
  </ul>

  <h3><a href="../../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">7.4.2. nilearn.decomposition.DictLearning</a><ul>
<li><a class="reference internal" href="#examples-using-nilearn-decomposition-dictlearning">7.4.2.1. Examples using <code class="docutils literal notranslate"><span class="pre">nilearn.decomposition.DictLearning</span></code></a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="nilearn.decomposition.CanICA.html"
                        title="previous chapter"><span class="section-number">7.4.1. </span>nilearn.decomposition.CanICA</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="nilearn.image.clean_img.html"
                        title="next chapter"><span class="section-number">7.5.1. </span>nilearn.image.clean_img</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="admonition note">
<p class="admonition-title">Note</p>
<p>This page is a reference documentation. It only explains the class
signature, and not how to use it. Please refer to the
<a class="reference internal" href="../../user_guide.html#user-guide"><span class="std std-ref">user guide</span></a> for the big picture.</p>
</div>
<div class="section" id="nilearn-decomposition-dictlearning">
<h1><span class="section-number">7.4.2. </span>nilearn.decomposition.DictLearning<a class="headerlink" href="#nilearn-decomposition-dictlearning" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="nilearn.decomposition.DictLearning">
<em class="property">class </em><code class="sig-prename descclassname">nilearn.decomposition.</code><code class="sig-name descname">DictLearning</code><span class="sig-paren">(</span><em class="sig-param">n_components=20</em>, <em class="sig-param">n_epochs=1</em>, <em class="sig-param">alpha=10</em>, <em class="sig-param">reduction_ratio='auto'</em>, <em class="sig-param">dict_init=None</em>, <em class="sig-param">random_state=None</em>, <em class="sig-param">batch_size=20</em>, <em class="sig-param">method='cd'</em>, <em class="sig-param">mask=None</em>, <em class="sig-param">smoothing_fwhm=4</em>, <em class="sig-param">standardize=True</em>, <em class="sig-param">detrend=True</em>, <em class="sig-param">low_pass=None</em>, <em class="sig-param">high_pass=None</em>, <em class="sig-param">t_r=None</em>, <em class="sig-param">target_affine=None</em>, <em class="sig-param">target_shape=None</em>, <em class="sig-param">mask_strategy='epi'</em>, <em class="sig-param">mask_args=None</em>, <em class="sig-param">n_jobs=1</em>, <em class="sig-param">verbose=0</em>, <em class="sig-param">memory=Memory(location=None)</em>, <em class="sig-param">memory_level=0</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.decomposition.DictLearning" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform a map learning algorithm based on spatial component sparsity,
over a CanICA initialization.  This yields more stable maps than CanICA.</p>
<blockquote>
<div><div class="versionadded">
<p><span class="versionmodified added">New in version 0.2.</span></p>
</div>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>mask: Niimg-like object or MultiNiftiMasker instance, optional</strong></dt><dd><p>Mask to be used on data. If an instance of masker is passed,
then its mask will be used. If no mask is given,
it will be computed automatically by a MultiNiftiMasker with default
parameters.</p>
</dd>
<dt><strong>n_components: int</strong></dt><dd><p>Number of components to extract. By default n_components=20.</p>
</dd>
<dt><strong>batch_size</strong><span class="classifier">int, optional, default=20</span></dt><dd><p>The number of samples to take in each batch.</p>
</dd>
<dt><strong>n_epochs: float, default=1</strong></dt><dd><p>Number of epochs the algorithm should run on the data.</p>
</dd>
<dt><strong>alpha: float, optional, default=10</strong></dt><dd><p>Sparsity controlling parameter.</p>
</dd>
<dt><strong>dict_init: Niimg-like object, optional</strong></dt><dd><p>Initial estimation of dictionary maps. Would be computed from CanICA if
not provided.</p>
</dd>
<dt><strong>reduction_ratio: ‘auto’ or float between 0. and 1.</strong></dt><dd><ul class="simple">
<li><p>Between 0. or 1. : controls data reduction in the temporal domain.
1. means no reduction, &lt; 1. calls for an SVD based reduction.</p></li>
<li><p>if set to ‘auto’, estimator will set the number of components per
reduced session to be n_components.</p></li>
</ul>
</dd>
<dt><strong>method</strong><span class="classifier">{‘lars’, ‘cd’}, default=’cd’</span></dt><dd><p>Coding method used by sklearn backend. Below are the possible values.
lars: uses the least angle regression method to solve the lasso problem
(linear_model.lars_path)
cd: uses the coordinate descent method to compute the
Lasso solution (linear_model.Lasso). Lars will be faster if
the estimated components are sparse.</p>
</dd>
<dt><strong>random_state: int or RandomState</strong></dt><dd><p>Pseudo number generator state used for random sampling.</p>
</dd>
<dt><strong>smoothing_fwhm: float, optional, default=4mm</strong></dt><dd><p>If smoothing_fwhm is not None, it gives the size in millimeters of the
spatial smoothing to apply to the signal.</p>
</dd>
<dt><strong>standardize</strong><span class="classifier">boolean, optional, default=True</span></dt><dd><p>If standardize is True, the time-series are centered and normed:
their variance is put to 1 in the time dimension.</p>
</dd>
<dt><strong>detrend</strong><span class="classifier">boolean, optional, default=True</span></dt><dd><p>If detrend is True, the time-series will be detrended before
components extraction.</p>
</dd>
<dt><strong>target_affine: 3x3 or 4x4 matrix, optional</strong></dt><dd><p>This parameter is passed to image.resample_img. Please see the
related documentation for details.</p>
</dd>
<dt><strong>target_shape: 3-tuple of integers, optional</strong></dt><dd><p>This parameter is passed to image.resample_img. Please see the
related documentation for details.</p>
</dd>
<dt><strong>low_pass: None or float, optional</strong></dt><dd><p>This parameter is passed to signal.clean. Please see the related
documentation for details.</p>
</dd>
<dt><strong>high_pass: None or float, optional</strong></dt><dd><p>This parameter is passed to signal.clean. Please see the related
documentation for details.</p>
</dd>
<dt><strong>t_r: float, optional</strong></dt><dd><p>This parameter is passed to signal.clean. Please see the related
documentation for details.</p>
</dd>
<dt><strong>mask_strategy: {‘background’, ‘epi’ or ‘template’}, optional</strong></dt><dd><p>The strategy used to compute the mask: use ‘background’ if your
images present a clear homogeneous background, ‘epi’ if they
are raw EPI images, or you could use ‘template’ which will
extract the gray matter part of your data by resampling the MNI152
brain mask for your data’s field of view.
Depending on this value, the mask will be computed from
masking.compute_background_mask, masking.compute_epi_mask or
masking.compute_gray_matter_mask. Default is ‘epi’.</p>
</dd>
<dt><strong>mask_args: dict, optional</strong></dt><dd><p>If mask is None, these are additional parameters passed to
masking.compute_background_mask or masking.compute_epi_mask
to fine-tune mask computation. Please see the related documentation
for details.</p>
</dd>
<dt><strong>memory: instance of joblib.Memory or string</strong></dt><dd><p>Used to cache the masking process.
By default, no caching is done. If a string is given, it is the
path to the caching directory.</p>
</dd>
<dt><strong>memory_level: integer, optional</strong></dt><dd><p>Rough estimator of the amount of memory used by caching. Higher value
means more memory for caching.</p>
</dd>
<dt><strong>n_jobs: integer, optional, default=1</strong></dt><dd><p>The number of CPUs to use to do the computation. -1 means
‘all CPUs’, -2 ‘all CPUs but one’, and so on.</p>
</dd>
<dt><strong>verbose: integer, optional</strong></dt><dd><p>Indicate the level of verbosity. By default, nothing is printed.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Arthur Mensch, Gael Varoquaux, Bertrand Thirion,
Compressed online dictionary learning for fast resting-state fMRI
decomposition.
IEEE 13th International Symposium on Biomedical Imaging (ISBI), 2016.
pp. 1282-1285</p></li>
</ul>
<dl class="field-list">
<dt class="field-odd">Attributes</dt>
<dd class="field-odd"><dl>
<dt><strong>`components_`</strong><span class="classifier">2D numpy array (n_components x n-voxels)</span></dt><dd><p>Masked dictionary components extracted from the input images.</p>
<p>Deprecated since version 0.4.1. Use <cite>components_img_</cite> instead</p>
</dd>
<dt><strong>`components_img_`</strong><span class="classifier">4D Nifti image</span></dt><dd><p>4D image giving the extracted components. Each 3D image is a component.</p>
<p>New in version 0.4.1.</p>
</dd>
<dt><strong>`masker_`</strong><span class="classifier">instance of MultiNiftiMasker</span></dt><dd><p>Masker used to filter and mask data as first step. If an instance of
MultiNiftiMasker is given in <cite>mask</cite> parameter,
this is a copy of it. Otherwise, a masker is created using the value
of <cite>mask</cite> and other NiftiMasker related parameters as initialization.</p>
</dd>
<dt><strong>`mask_img_`</strong><span class="classifier">Niimg-like object</span></dt><dd><p>See <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">http://nilearn.github.io/manipulating_images/input_output.html</a>
The mask of the data. If no mask was given at masker creation, contains
the automatically computed mask.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="method">
<dt id="nilearn.decomposition.DictLearning.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">n_components=20</em>, <em class="sig-param">n_epochs=1</em>, <em class="sig-param">alpha=10</em>, <em class="sig-param">reduction_ratio='auto'</em>, <em class="sig-param">dict_init=None</em>, <em class="sig-param">random_state=None</em>, <em class="sig-param">batch_size=20</em>, <em class="sig-param">method='cd'</em>, <em class="sig-param">mask=None</em>, <em class="sig-param">smoothing_fwhm=4</em>, <em class="sig-param">standardize=True</em>, <em class="sig-param">detrend=True</em>, <em class="sig-param">low_pass=None</em>, <em class="sig-param">high_pass=None</em>, <em class="sig-param">t_r=None</em>, <em class="sig-param">target_affine=None</em>, <em class="sig-param">target_shape=None</em>, <em class="sig-param">mask_strategy='epi'</em>, <em class="sig-param">mask_args=None</em>, <em class="sig-param">n_jobs=1</em>, <em class="sig-param">verbose=0</em>, <em class="sig-param">memory=Memory(location=None)</em>, <em class="sig-param">memory_level=0</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.decomposition.DictLearning.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize self.  See help(type(self)) for accurate signature.</p>
</dd></dl>

<dl class="method">
<dt id="nilearn.decomposition.DictLearning.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">imgs</em>, <em class="sig-param">y=None</em>, <em class="sig-param">confounds=None</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.decomposition.DictLearning.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the mask and the components across subjects</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>imgs: list of Niimg-like objects</strong></dt><dd><p>See <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">http://nilearn.github.io/manipulating_images/input_output.html</a>
Data on which the mask is calculated. If this is a list,
the affine is considered the same for all.</p>
</dd>
<dt><strong>confounds</strong><span class="classifier">list of CSV file paths or 2D matrices</span></dt><dd><p>This parameter is passed to nilearn.signal.clean. Please see the
related documentation for details. Should match with the list
of imgs given.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">object</span></dt><dd><p>Returns the instance itself. Contains attributes listed
at the object level.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nilearn.decomposition.DictLearning.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">X</em>, <em class="sig-param">y=None</em>, <em class="sig-param">**fit_params</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.decomposition.DictLearning.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">numpy array of shape [n_samples, n_features]</span></dt><dd><p>Training set.</p>
</dd>
<dt><strong>y</strong><span class="classifier">numpy array of shape [n_samples]</span></dt><dd><p>Target values.</p>
</dd>
<dt><strong>**fit_params</strong><span class="classifier">dict</span></dt><dd><p>Additional fit parameters.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>X_new</strong><span class="classifier">numpy array of shape [n_samples, n_features_new]</span></dt><dd><p>Transformed array.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nilearn.decomposition.DictLearning.get_params">
<code class="sig-name descname">get_params</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.decomposition.DictLearning.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>deep</strong><span class="classifier">bool, default=True</span></dt><dd><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>params</strong><span class="classifier">mapping of string to any</span></dt><dd><p>Parameter names mapped to their values.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nilearn.decomposition.DictLearning.inverse_transform">
<code class="sig-name descname">inverse_transform</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">loadings</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.decomposition.DictLearning.inverse_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Use provided loadings to compute corresponding linear component
combination in whole-brain voxel space</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>loadings: list of numpy array (n_samples x n_components)</strong></dt><dd><p>Component signals to tranform back into voxel signals</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>reconstructed_imgs: list of nibabel.Nifti1Image</dt><dd><p>For each loading, reconstructed Nifti1Image</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nilearn.decomposition.DictLearning.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">imgs</em>, <em class="sig-param">confounds=None</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.decomposition.DictLearning.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score function based on explained variance on imgs.</p>
<p>Should only be used by DecompositionEstimator derived classes</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>imgs: iterable of Niimg-like objects</strong></dt><dd><p>See <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">http://nilearn.github.io/manipulating_images/input_output.html</a>
Data to be scored</p>
</dd>
<dt><strong>confounds: CSV file path or 2D matrix</strong></dt><dd><p>This parameter is passed to nilearn.signal.clean. Please see the
related documentation for details</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>score: float,</dt><dd><p>Holds the score for each subjects. Score is two dimensional
if per_component is True. First dimension
is squeezed if the number of subjects is one</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nilearn.decomposition.DictLearning.set_params">
<code class="sig-name descname">set_params</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">**params</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.decomposition.DictLearning.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s possible to update each
component of a nested object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>**params</strong><span class="classifier">dict</span></dt><dd><p>Estimator parameters.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">object</span></dt><dd><p>Estimator instance.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nilearn.decomposition.DictLearning.transform">
<code class="sig-name descname">transform</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">imgs</em>, <em class="sig-param">confounds=None</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.decomposition.DictLearning.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Project the data into a reduced representation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>imgs: iterable of Niimg-like objects</strong></dt><dd><p>See <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">http://nilearn.github.io/manipulating_images/input_output.html</a>
Data to be projected</p>
</dd>
<dt><strong>confounds: CSV file path or 2D matrix</strong></dt><dd><p>This parameter is passed to nilearn.signal.clean. Please see the
related documentation for details</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>loadings: list of 2D ndarray,</dt><dd><p>For each subject, each sample, loadings for each decomposition
components
shape: number of subjects * (number of scans, number of regions)</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<div class="section" id="examples-using-nilearn-decomposition-dictlearning">
<h2><span class="section-number">7.4.2.1. </span>Examples using <code class="docutils literal notranslate"><span class="pre">nilearn.decomposition.DictLearning</span></code><a class="headerlink" href="#examples-using-nilearn-decomposition-dictlearning" title="Permalink to this headline">¶</a></h2>
<div class="sphx-glr-thumbcontainer" tooltip="Various approaches exist to derive spatial maps or networks from group fmr data. The methods ex..."><div class="figure align-default" id="id1">
<img alt="../../_images/sphx_glr_plot_compare_decomposition_thumb.png" src="../../_images/sphx_glr_plot_compare_decomposition_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_compare_decomposition.html#sphx-glr-auto-examples-03-connectivity-plot-compare-decomposition-py"><span class="std std-ref">Deriving spatial maps from group fMRI data using ICA and Dictionary Learning</span></a></span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to use nilearn.regions.RegionExtractor to extract spatially constrained ..."><div class="figure align-default" id="id2">
<img alt="../../_images/sphx_glr_plot_extract_regions_dictlearning_maps_thumb.png" src="../../_images/sphx_glr_plot_extract_regions_dictlearning_maps_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html#sphx-glr-auto-examples-03-connectivity-plot-extract-regions-dictlearning-maps-py"><span class="std std-ref">Regions extraction using Dictionary Learning and functional connectomes</span></a></span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</div>
</div><div style='clear:both'></div></div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>

    <div class="footer">
            &copy; The nilearn developers 2010-2015.
          Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 2.3.1.
        <span style="padding-left: 5ex;">
          <a href="../../_sources/modules/generated/nilearn.decomposition.DictLearning.rst.txt"
        	 rel="nofollow">Show this page source</a>
        </span>
    </div>
  </body>
</html>